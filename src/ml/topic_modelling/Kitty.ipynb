{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1665065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ippk93/anaconda3/envs/made_1/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.models.kitty_classifier import Kitty\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from nltk.corpus import stopwords\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15732401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_tm.subset import get_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8f5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(10)\n",
    "# torch.cuda.manual_seed(10)\n",
    "# np.random.seed(10)\n",
    "# random.seed(10)\n",
    "# torch.backends.cudnn.enabled = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9296709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/23 02:56:54 WARN Utils: Your hostname, PK resolves to a loopback address: 127.0.1.1; using 172.28.78.27 instead (on interface eth0)\n",
      "22/10/23 02:56:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/10/23 02:56:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Kitty\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a89b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../../notebooks/MADE/data.parquet'  # Input path to dataset in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7d6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ids, abstracts = get_data_sample(spark=spark, data_path=DATA_PATH, sample_frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5438d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('556fa3b02401b4b38c237522',\n",
       "  'An N:1 protection mechanism is proposed to reduce backup OLTs in a resilient dual-homed LR-PON deployment. We model the problem as an Integer Linear Program and solve it for an Irish network deployment.'),\n",
       " ('556fa12b2401b4b38c237465',\n",
       "  'Multi-tenant data centers provide a cost-effective many-server infrastructure for hosting large-scale applications. These data centers can run multiple virtual machines (VMs) for each tenant, and potentially place any of these VMs on any of the servers. Therefore, for inter-VM communication, they also need to provide a VM resolution method that can quickly determine the server location of any VM. Unfortunately, existing methods suffer from a scalability bottleneck in the network load of the address resolution messages and/or in the size of the resolution tables. In this paper, we propose Smart Address Learning (SAL), a novel approach that expands the scalability of both the network load and the resolution table sizes, making it implementable on faster memory devices. The key property of the approach is to selectively learn the addresses in the resolution tables, by using the fact that the VMs of different tenants do not communicate. We further compare the various resolution methods and analyze the tradeoff between network load and table sizes. We also evaluate our results using real-life trace simulations. Our analysis shows that SAL can reduce both the network load and the resolution table sizes by several orders of magnitude.'),\n",
       " ('556fabc52401b4b38c237748',\n",
       "  'Retinal images are obtained using a fundus camera in order to evaluate many important diseases such as Diabetic Retinopathy and Glaucoma. Sometimes, the images appear as uniformly illuminated, have luminosity and contrast variability. This problem can be severely compromised the diagnostic process and the results, especially if automated computer-based procedure is used to derive the parameters of diagnostic. Many researchers propose different approaches to normalize the badly illuminated images based on filtering techniques. In this paper, we compare a six (6) type of filtering techniques and applied to the retinal images from Digital Retinal Images for Vessel Extraction (DRIVE) database to adjust the contrast variation and illumination in order to produce a better diagnostic result. The result performance is evaluate based on Signal Noise Ratio (SNR) and Mean Square Error (MSE) is compared to the other filtering methods. From the result, the Homomorphic filtering based on high pass filter obtained higher SNR value which is 3.093 and the lowest in MSE which is 71267.51.'),\n",
       " ('556fb32a2401b4b38c237954',\n",
       "  'In this study, a theoretical model for the combination of all individual questions from a questionnaire is investigated. For this implementation, a well-fitted Elman neural network is used in order to formulate the weighting relations between questions of the questionnaire which is produced for the project “Innovative Services to Strengthen Cooperation and Internationalization between SMEs” (I.S.C.I.) which has as objective the internationalization processes of the agro food industry of the Small and Medium-sized Enterprises (SMEs) (in Apulia Region, Italy, and in Ionian Islands, Greece). The aim of this study is the evaluation of the above questionnaire using a data mining technique in which the mental processing of an expert is linking with the Elman Neural Network. For this reason a proper questionnaire was used in order to classify the SMEs into three (3) classes according to their performance.'),\n",
       " ('556fb8db2401b4b38c237af0',\n",
       "  'The Greeks measure the rate of change of (financial) derivative prices with respect to underlying market parameters, which is essential in financial risk management. This paper focuses on a modified pathwise method that overcomes the difficulty of estimating Greeks with discontinuous payoffs as well as second-order Greeks and involves a kernel estimator whose accuracy/performance relies on a smoothing parameter (bandwidth). We explore the accuracy of the Greek delta, vega, and theta estimators of Asian digital options and up-and-out barrier call options with varying bandwidths. In addition, we investigate the sensitivity of a proposed iterative scheme that generates the “optimal” bandwidth. Our numerical experiments indicate that the Greek estimators are quite sensitive to the bandwidth choice, and the “optimal” bandwidth generated is sensitive to input parameters.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(ids[:5], abstracts[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffbfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52947e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/ippk93/.cache/torch/sentence_transformers/allenai_scibert_scivocab_uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/ippk93/.cache/torch/sentence_transformers/allenai_scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397ba3f4e3d04f2c981f41178a4d3220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [147570/147570]\tTrain Loss: 454.0544805007793\tTime: 0:00:03.230704: : 5it [00:16,  3.20s/it] \n",
      "Sampling: [20/20]: : 20it [00:37,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "kt = Kitty()\n",
    "kt.train(abstracts, topics=10, embedding_model=\"allenai/scibert_scivocab_uncased\", stopwords_list=list(stop_words), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde5d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['data', 'learning', 'based', 'classification', 'text', 'set', 'results', 'method', 'approach', 'mining'])\n",
      "(1, ['performance', 'network', 'transmission', 'power', 'channel', 'energy', 'proposed', 'wireless', 'scheme', 'interference'])\n",
      "(2, ['software', 'development', 'process', 'systems', 'information', 'tools', 'design', 'research', 'knowledge', 'use'])\n",
      "(3, ['image', 'method', 'images', 'using', 'based', 'proposed', 'segmentation', 'resolution', 'algorithm', 'recognition'])\n",
      "(4, ['problem', 'control', 'model', 'algorithm', 'numerical', 'time', 'linear', 'nonlinear', 'problems', 'optimization'])\n",
      "(5, ['services', 'data', 'network', 'service', 'applications', 'cloud', 'systems', 'security', 'distributed', 'application'])\n",
      "(6, ['conditional', 'parallelism', 'commercial', 'page', 'operate', 'additionally', 'back', 'commonly', 'quasi', 'latter'])\n",
      "(7, ['robot', 'human', 'students', 'learning', 'interaction', 'subjects', 'study', 'using', 'user', 'social'])\n",
      "(8, ['networking', 'advances', 'media', 'companies', 'parallelism', 'integrating', 'technology', 'cpu', 'activities', 'across'])\n",
      "(9, ['graphs', 'approximation', 'graph', 'given', 'probability', 'codes', 'maximum', 'length', 'random', 'simple'])\n"
     ]
    }
   ],
   "source": [
    "print(*[(i, kt.get_word_classes(10)[i]) for i in range(10)], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e029f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kt.assigned_classes = {\n",
    "    0 : \"machine learning\",\n",
    "    1 : \"Distributed systems\",\n",
    "    2 : \"Software development\",\n",
    "    3 : \"Computer vision\",\n",
    "    4 : \"Signal processing\",\n",
    "    5 : \"Cloud & Web\",\n",
    "    6 : \"other\",\n",
    "    7 : \"Motion systems\",\n",
    "    8 : \"Networks\",\n",
    "    9 : \"Graphs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569c322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/ippk93/.cache/torch/sentence_transformers/allenai_scibert_scivocab_uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/ippk93/.cache/torch/sentence_transformers/allenai_scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b5af9237584a01bc1c71ccc882d92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [20/20]: : 20it [00:10,  1.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Distributed systems']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Dynamic Voltage and Frequency Scaling (DVFS) is commonly used to save energy in computing systems.\n",
    "However, when it comes to parallel programs, existing DVFS controllers only reduce frequency while or before waiting in blocking communications. As a consequence, energy savings are only possible for the program tasks out of the critical path and when the workload is imbalanced.\n",
    "We propose a new runtime DVFS controller, FoREST-mn.\n",
    "It allows to take advantage of both the low CPU usage of some program phases as well as communication slack to save more energy with parallel programs.\n",
    "The DVFS control then becomes more complex, but energy savings are even obtained when the workload is balanced.\n",
    "The resulting slowdown on programs is carefully controlled and constrained by a user-defined threshold.\n",
    "We implemented the presented strategies and evaluated it on 4 compute nodes totaling 64 cores.\n",
    "FoREST-mn is able to perform significant CPU energy savings on the NAS programs, up to 34 % on MG, while efficiently bounding the resulting slowdown.\n",
    "\"\"\"\n",
    "\n",
    "kt.predict([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef896d",
   "metadata": {},
   "source": [
    "### See results of trained (on another sample) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3db6ee",
   "metadata": {},
   "source": [
    "#### Результаты ниже могут не работать, это нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccd9de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet = spark.read.parquet('contextualized_tm/preds.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95cc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parquet.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5bf0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_id</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>556fa6752401b4b38c2375ea</td>\n",
       "      <td>Robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556faa7e2401b4b38c2376ef</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>556fab9a2401b4b38c23773c</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>556fabc12401b4b38c237744</td>\n",
       "      <td>Signal Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>556fabc52401b4b38c237748</td>\n",
       "      <td>Computer Vision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     old_id              theme\n",
       "0  556fa6752401b4b38c2375ea           Robotics\n",
       "1  556faa7e2401b4b38c2376ef              other\n",
       "2  556fab9a2401b4b38c23773c         Algorithms\n",
       "3  556fabc12401b4b38c237744  Signal Processing\n",
       "4  556fabc52401b4b38c237748    Computer Vision"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35562a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                           9658\n",
       "Computer Vision                                 6676\n",
       "Project Development                             6042\n",
       "Worldwide Web                                   5839\n",
       "Graph Theory                                    5587\n",
       "Software Verification                           5481\n",
       "Algorithms                                      5407\n",
       "Robotics                                        5380\n",
       "Natural Language Processing                     5339\n",
       "Recommendation Systems                          5219\n",
       "Learning Courses                                5090\n",
       "Computer Medicine                               5085\n",
       "Machine Learning                                5044\n",
       "Optimization Methods                            4966\n",
       "Software Engineering                            4919\n",
       "Signal Processing                               4845\n",
       "Formal Systems                                  4788\n",
       "Databases                                       4739\n",
       "Devices                                         4702\n",
       "Networking & Internet Architecture              4658\n",
       "Informational Security                          4649\n",
       "Electrical Engineering                          4636\n",
       "Product & Marketing                             4561\n",
       "Differential Equations                          4517\n",
       "Radioelectronics                                4432\n",
       "Stability Theory                                3837\n",
       "Bioinformatics                                  3820\n",
       "Distributed, Parallel, and Cluster Computing    3638\n",
       "Control systems                                 2532\n",
       "Name: theme, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['theme'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9be599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338882576016867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['theme'] != 'other']) / len(df['theme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b925188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
